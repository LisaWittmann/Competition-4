{"metadata":{"kernelspec":{"name":"ir","display_name":"R","language":"R"},"language_info":{"mimetype":"text/x-r-source","name":"R","pygments_lexer":"r","version":"3.6.0","file_extension":".r","codemirror_mode":"r"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Emotion from Facial Expression\n\n## Big Data Analytics\n\n#### Group 9:\n\n*Roman Esseveld <br>\nLisa Wittmann <br>\nCharlotte Hartstein*\n\n**October 16, 2023 <br>\nUniversity of Amsterdam**","metadata":{}},{"cell_type":"markdown","source":"## *Table of Contents*\n\n[1. Libraries](#section-one) <br>\n\n[2. Introduction to Data](#section-two) <br>\n\n[3. Features](#section-three) <br>\n [3.1 Raw Pixel features](#subsection-three-models) <br>\n [3.2 Histogram features](#subsection-three-models) <br>\n\n[4. Data Preparation](#section-four) <br>\n [4.1 Putting all features together](#subsection-four-models) <br>\n [4.2 Data Cleaning](#subsection-four-models) <br>\n\n[5. Models](#section-five) <br>\n [5.1 Ridge Multinominal Regression](#subsection-five-models) <br>\n [5.2 Linear Discriminant Analysis](#subsection-five-models) <br>\n [5.3 Classification Tree](#subsection-five-models) <br>\n [5.4 Random Forest](#subsection-five-models) <br>\n [5.5 Boosted Trees](#subsection-five-models) <br>\n [5.6 Support Vector Machines](#subsection-five-models) <br>\n\n\n[6. Model Comparison](#section-six) <br>\n\n[7. Submissions](#section-seven) <br>\n\n[8. References](#section-eight) <br>","metadata":{}},{"cell_type":"code","source":"# 1 Libraries","metadata":{"execution":{"iopub.status.busy":"2023-10-19T09:22:37.009671Z","iopub.execute_input":"2023-10-19T09:22:37.010484Z","iopub.status.idle":"2023-10-19T09:22:37.015761Z","shell.execute_reply.started":"2023-10-19T09:22:37.010445Z","shell.execute_reply":"2023-10-19T09:22:37.014345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Importing packages\nlibrary(tidyverse) \nlibrary(png)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(randomForest)\nlibrary(doMC)\nsuppressMessages(library(tidytext))\nsuppressMessages(library(caret))\nsuppressMessages(library(glmnet))","metadata":{"_uuid":"051d70d956493feee0c6d64651c6a088724dca2a","_execution_state":"idle","execution":{"iopub.status.busy":"2023-10-19T09:34:04.013277Z","iopub.execute_input":"2023-10-19T09:34:04.013658Z","iopub.status.idle":"2023-10-19T09:34:04.037462Z","shell.execute_reply.started":"2023-10-19T09:34:04.013627Z","shell.execute_reply":"2023-10-19T09:34:04.036326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2 Introduction to Data\n### 2.1 Task and Goal\n\nThe objective of this project is to create a model capable of discerning emotions based on facial expressions. In this document, we will elucidate our approach for achieving this aim and outline the sequential stages involved in constructing the model. The targeted emotions for prediction encompass happiness, anger, sadness, and disgust. We have sourced our image data from the well-established Cohn-Kanade database, which comprises static images extracted from videos wherein individuals were instructed to convey these four distinct emotions through their facial expressions. The database was designed with the explicit purpose of facilitating machine learning endeavors, specifically for training and testing algorithms geared towards automated emotion classification.\n\n\n### 2.2 Dataset\nThe dataset we are working with is derived from the CK+ database, a well-established resource containing images and videos of individuals expressing various emotions. Our dataset comprises a total of 2,538 images in the training set and 1,080 images in the test set.\n\nTo facilitate image processing, we have structured these images as long vectors, with pixel intensities arranged row by row. Each image in the training set is also accompanied by an emotion label, categorizing it into emotions like anger, disgust, happiness, and sadness.\n\nFor the purpose of diversifying our training data and providing variations from different angles, certain images have been duplicated and subjected to slight rotations. All the images are monochromatic and have been standardized to a size of 48x48 pixels. It's important to note that the images we've used are a carefully curated subset of the CK+ database.\n\n### 2.3 Candidate Machine Learning Models and Features\nThe classification task on hand deals with a multiple classification problem - people expressing the four emotions. Furthermore, we are working with the raw pixels and therefore will face a lot of features, which we can derive from the visual outline. Therefore we chose the following features to include in those models: \n\n- **histogram features**: We created a document-by-term matrix which contains \n\n\nAnd our predictions of facial expressions were based on the following models: \n\n- Ridge Multinominal Regression <br>\n- Linear Discriminant Analysis <br>\n- Classification Tree <br>\n- Random Forest <br>\n- Support Vector Machines]\n\n### 2.4 Bayes' error bound\nTo get an idea of the minimum accuracy we should aim for (the Bayes bound), we can look at how good humans are at recognizing emotions from facial expressions. Our brains are pretty good at this because we have a built-in understanding of emotions, and we see faces as a whole picture, not just a bunch of separate features like eyes, nose, and lips. This holistic view helps us make more accurate emotional guesses.\n\nOn the other hand, machine learning algorithms analyze individual features without really understanding the big emotional picture. Plus, we humans have our own emotions and can easily connect facial expressions to feelings. Algorithms can't do that.\n\nSo, to figure out the Bayes bound, we need to know how often humans get it right. In a study by Mollahosseini and others in 2018, they checked how often human judges correctly guessed 11 emotions. For the emotions in our dataset, here are the percentages they identified correctly:\n\n\n<table>\n    <thead>\n    <tr><td>disgust</td><td>anger</td><td>happy</td><td>sad</td></tr>\n    </thead>\n    <tbody>\n        <tr><td>67.6%</td><td>62.3%</td><td>79.6%</td><td>69.7%</td></tr>\n    </tbody>\n</table>\n\n\nOur estimated accuracy serves as as the \"Bayes bound\" or the best performance we can reasonably expect. This suggests that a very good machine learning model is unlikely to outperform humans in recognising these emotions from facial expressions. We compute the probable overall Bayes bound for this specific dataset, which amounts to 71%.\n\nEstimated Accuracy = [(0.623 * 570) + (0.676 * 744) + (0.796 * 870) + (0.697 * 354)] / (2538) * 100% ≈ 71%","metadata":{}},{"cell_type":"markdown","source":"### 2.5 Data Import","metadata":{}},{"cell_type":"markdown","source":"First, we load image data, where it reads image files and stores pixel values in a matrix X. Class labels are stored in a vector y.\nThe row and column names of X are modified for better readability.","metadata":{}},{"cell_type":"code","source":"# Data Import\nlist.files(path = \"../input/\")\n\n# Show the availabe directories\ndirs = dir(\"../input\", pattern=\"[^g]$\", recursive=TRUE, include.dirs = TRUE, full.names = TRUE)\n\n# Get all image files: file names ending \".png\" \nanger   = dir(grep(\"anger\",   dirs, value = TRUE), pattern = \"png$\", full.names = TRUE)\ndisgust = dir(grep(\"disgust\", dirs, value = TRUE), pattern = \"png$\", full.names = TRUE)\nhappy   = dir(grep(\"happy\",   dirs, value = TRUE), pattern = \"png$\", full.names = TRUE)\nsad     = dir(grep(\"sad\",     dirs, value = TRUE), pattern = \"png$\", full.names = TRUE)\ntest_im = dir(grep(\"test\",    dirs, value = TRUE), pattern = \"png$\", full.names = TRUE)\n\nstr(anger)\nstr(disgust)\nstr(happy)\nstr(sad)\nstr(test_im)","metadata":{"execution":{"iopub.status.busy":"2023-10-19T09:22:37.047805Z","iopub.status.idle":"2023-10-19T09:22:37.048264Z","shell.execute_reply.started":"2023-10-19T09:22:37.048009Z","shell.execute_reply":"2023-10-19T09:22:37.048037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Combine all filenames into a single vector\ntrain_image_files = c(anger, happy, sad, disgust)\n\n# Read in the images as pixel values (discarding color channels)\nX = sapply(train_image_files, function(nm) c(readPNG(nm)[,,1])) %>% t() \ny = c(rep(\"anger\", length(anger)), rep(\"happy\", length(happy)), rep(\"sad\", length(sad)), rep(\"disgust\", length(disgust)))\n\nX_test = sapply(test_im, function(nm) c(readPNG(nm)[,,1])) %>% t() \n\n\n# Change row and column names of X to something more managable (caret::train requires column names)\nrownames(X)      = gsub(\".+train/\", \"\", rownames(X))\nrownames(X_test) = gsub(\".+test/\",  \"\", rownames(X_test))\n\ncolnames(X) = colnames(X_test) = paste(\"p\",1:ncol(X), sep=\"\")\n\n# Check result (are X, X_test, and y what we expect)\nX[1:6,20:23] %>% print\ntable(y)\n                \nX_test[1:6,20:23] %>% print\n","metadata":{"execution":{"iopub.status.busy":"2023-10-19T09:22:37.049437Z","iopub.status.idle":"2023-10-19T09:22:37.050196Z","shell.execute_reply.started":"2023-10-19T09:22:37.049972Z","shell.execute_reply":"2023-10-19T09:22:37.049993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualization utility function\nas_image = function(x, nr=sqrt(length(x))) {opar=par(mar=rep(0,4)); on.exit(par(opar)); image(t(matrix(x,nr))[,nr:1], col = gray(0:255/255),axes=F)}\n\n\noptions(repr.plot.width=4, repr.plot.height=4)\nas_image(X[13,])\nas_image(X_test[13,])","metadata":{"execution":{"iopub.status.busy":"2023-10-19T09:22:37.051717Z","iopub.status.idle":"2023-10-19T09:22:37.052275Z","shell.execute_reply.started":"2023-10-19T09:22:37.051982Z","shell.execute_reply":"2023-10-19T09:22:37.052007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3 Features\n","metadata":{}},{"cell_type":"markdown","source":"### 3.1 Histogram features\n\nDetecting edges in images is important for accurate emotion recognition. Edges are most effectively identified in grayscale images because they filter out variations in illumination and different skin colors. These variations can facilitate emotion recognition.\n\nHistogram features are particularly effective when applied to edges. To detect edges, we examine the rapid changes in pixel intensities. By computing the difference between two consecutive pixels and checking if it exceeds a certain threshold, we can locate the pixels representing the edges of abrupt intensity changes. This process can be performed in various directions, such as north, south, west, east, north-west, and south-west. However, to simplify the process, it suffices to compute differences in just two directions: north and west (or alternatively, south and east). These directions help identify horizontal and vertical edges, effectively filtering out pixels that are part of diagonal edges.\n\nThe FreySlateFeatures are computed by applying the edges function to X. This function calculates edge features for the input images and stores them in data frames.","metadata":{}},{"cell_type":"code","source":"options(repr.plot.width=4*4, repr.plot.height=4)\n\n# Compute edges by differencing neighboring pixels\nim = matrix(X[2000,],48)\nh_edge = im[-1,] - im[-48,] # horizontal\nv_edge = im[,-1] - im[,-48] # vertical\nd_edge = h_edge[,-1] - h_edge[,-48] # diagonal\n\n# Specify a threshold for edge pixels\nthreshold = .0625 \n\nlayout(t(1:4))\nas_image(im)\nas_image(h_edge < threshold,   47); mtext(\"horizontal edge pixels\")\nas_image(v_edge < threshold,   48); mtext(\"vertical edge pixels\")\nas_image(d_edge < threshold/2, 47); mtext(\"diagonal edge pixels\")\n#as_image((h_edge[,-1] < 0.1) & (v_edge[-1,] < 0.1), 47); mtext(\"edge pixels\")","metadata":{"execution":{"iopub.status.busy":"2023-10-19T09:22:37.05512Z","iopub.status.idle":"2023-10-19T09:22:37.056038Z","shell.execute_reply.started":"2023-10-19T09:22:37.055776Z","shell.execute_reply":"2023-10-19T09:22:37.055802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load FreySlateFeatures function \nsource(\"https://bit.ly/32um24j\")\n\n# Creating a function to only keep those features mentioned\nFreySlate_fr = function (X){\n    features = FreySlateFeatures(X) \n}","metadata":{"execution":{"iopub.status.busy":"2023-10-19T09:22:37.057206Z","iopub.status.idle":"2023-10-19T09:22:37.058413Z","shell.execute_reply.started":"2023-10-19T09:22:37.058206Z","shell.execute_reply":"2023-10-19T09:22:37.058225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# frey slate feature function \nfrey_slate = function (X) {\n\n    #creating tibbles for storing edge features    \n    H = tibble()\n    V = tibble()\n    D = tibble()\n\n    # threshold for edge pixel\n    threshold = 0.0625\n    \n    x_len = nrow(X)\n    # looping to calculate all edge-related features\n    for (i in 1:x_len) { #  three types of edge matrices\n        im = matrix(X[i,],48)\n        h_edge = im[-1,] - im[-48,] # horizontal\n        v_edge = im[,-1] - im[,-48] # vertical\n        d_edge = h_edge[,-1] - h_edge[,-48] # diagonal\n        \n        # creating the freyslate features\n        H = bind_rows(H, FreySlate_fr(h_edge < threshold))\n        V = bind_rows(V, FreySlate_fr(v_edge < threshold))\n        D = bind_rows(D, FreySlate_fr(d_edge < threshold))\n\n    }\n    \n    # renaming \n    H = H %>%\n        rename_with(~paste0(., '_H'))\n    V = V %>%\n        rename_with(~paste0(., '_V'))\n    D = D %>%\n        rename_with(~paste0(., '_D'))\n    \n    # adding all our columns into matrix\n    frey_slate_df = X %>%\n    cbind(H) %>%\n    cbind(V) %>%\n    cbind(D)\n    \n    return(frey_slate_df)\n}","metadata":{"execution":{"iopub.status.busy":"2023-10-19T09:22:37.059406Z","iopub.status.idle":"2023-10-19T09:22:37.060364Z","shell.execute_reply.started":"2023-10-19T09:22:37.060167Z","shell.execute_reply":"2023-10-19T09:22:37.060186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# histogram-based statistics function\nhist_stats <- function(px_value) {\n  num_bins <- 256  # Number of bins for the histogram\n  \n  # compute the histogram of px_value\n  hist_data <- hist(px_value, breaks = num_bins, plot = FALSE)\n  \n  # normalize histogram\n  hist_counts <- hist_data$counts / sum(hist_data$counts)\n  \n  # calculate histogram-based features\n  mean_val <- sum(hist_data$mids * hist_counts)\n  var_hist <- sum((hist_data$mids - mean_val)^2 * hist_counts)\n  skew_hist <- sum((hist_data$mids - mean_val)^3 * hist_counts) / (var_hist^1.5)\n  kurt_hist <- sum((hist_data$mids - mean_val)^4 * hist_counts) / (var_hist^2)\n  \n  return(c(mean_val, var_hist, skew_hist, kurt_hist))\n}","metadata":{"execution":{"iopub.status.busy":"2023-10-19T09:22:37.061252Z","iopub.status.idle":"2023-10-19T09:22:37.06203Z","shell.execute_reply.started":"2023-10-19T09:22:37.061836Z","shell.execute_reply":"2023-10-19T09:22:37.061854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Data Preparation\n## 4.1 Putting all features together\none time for the training set","metadata":{}},{"cell_type":"code","source":"# compute the Fray Slate features for trainig data\nfs_features_training = (frey_slate(X)) %>% \n    as_tibble(rownames = \"id\")\n\n# compute histogram based features for trainig data\nhist_features = hist_stats(X) %>% \n    as_tibble(rownames = \"id\")\n\n# apply it to one training set by id\nX_train_features = fs_features_training %>%\n    left_join(hist_features, by = \"id\")\n  \nX_raw_all = X %>%\n    as_tibble(rownames = \"id\")\n\n\nX_train_features = X_train_features[,-1]\nhead(X_train_features)","metadata":{"execution":{"iopub.status.busy":"2023-10-19T09:22:37.063166Z","iopub.status.idle":"2023-10-19T09:22:37.063542Z","shell.execute_reply.started":"2023-10-19T09:22:37.063362Z","shell.execute_reply":"2023-10-19T09:22:37.063379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"and creating the same features for the test set","metadata":{}},{"cell_type":"code","source":"# compute the Fray Slate features for test data\nfs_features_test = (frey_slate(X_test)) %>%\n     as_tibble(rownames = \"id\")\n\n# compute histogram based features for test data\nhist_features = hist_stats(X_test) %>% \n    as_tibble(rownames = \"id\")\n\n# apply it to one test set by id\nX_test_features = fs_features_test %>%\n    left_join(hist_features, by = \"id\") \n\nX_test_raw_all = X_test %>%\n    as_tibble(rownames = \"id\")\n\nX_test_features <- X_test_features[,-1]\nX_test_features <- as.data.frame(X_test_features)\nhead(X_test_features)","metadata":{"execution":{"iopub.status.busy":"2023-10-19T09:22:37.065234Z","iopub.status.idle":"2023-10-19T09:22:37.065914Z","shell.execute_reply.started":"2023-10-19T09:22:37.065716Z","shell.execute_reply":"2023-10-19T09:22:37.065738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.2 Data Cleaning","metadata":{}},{"cell_type":"markdown","source":"- Check for NearZero Variance\n- Check for highly correlated variables\n- Check for multicolloinearity BUT!\n\nWe clean the training data by first identifying near-zero variance measures and high pairwise correlations and then removing them.\n\n\nNote that Frey & Slate features were designed for distinguishing capital characters; not for distinguishing emotions in pictures of human faces. If you want to go this handicraft way of feature extraction you may want to consider chosing different histogram descriptors.\n\nYou will notice that not all features computed this way have non-zero variance, and it is generally dificult to predict which features are highly correlated or multi-collinear.","metadata":{}},{"cell_type":"code","source":"# checking for near-zero variance\nnear_zero <- caret::nearZeroVar(X_train_features)\n\n# removing the observations that show near-zero variance\ndata_train_clean <- X_train_features %>% \n    dplyr::select(-all_of(near_zero))\n\nhead(data_train_clean)","metadata":{"execution":{"iopub.status.busy":"2023-10-19T09:22:37.067212Z","iopub.status.idle":"2023-10-19T09:22:37.067581Z","shell.execute_reply.started":"2023-10-19T09:22:37.067417Z","shell.execute_reply":"2023-10-19T09:22:37.067435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking for high correlations\nhigh_corr <- cor(data_train_clean) %>% \n    # fine tuned the cutoff as too many feature were removed at 0.90\n    caret::findCorrelation(0.97)\n\n# removing the observations that show high correlations \ndata_train_clean <- data_train_clean %>% \n    dplyr::select(-all_of(high_corr))\n\nhead(data_train_clean)\n# convert tibble to data frame to facilitate model fitting\ndata_train_clean <- as.data.frame(data_train_clean)","metadata":{"execution":{"iopub.status.busy":"2023-10-19T09:22:37.068896Z","iopub.status.idle":"2023-10-19T09:22:37.069268Z","shell.execute_reply.started":"2023-10-19T09:22:37.069083Z","shell.execute_reply":"2023-10-19T09:22:37.069101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Cleaning the test set so the columns match the train set\n","metadata":{}},{"cell_type":"code","source":"X_test_clean <- X_test_features %>%\n  select(names(data_train_clean))\n\nhead(X_test_clean)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-19T09:22:37.070498Z","iopub.status.idle":"2023-10-19T09:22:37.070858Z","shell.execute_reply.started":"2023-10-19T09:22:37.070695Z","shell.execute_reply":"2023-10-19T09:22:37.070712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Models\n\nTo determine the optimal balance between bias and variance, accuracy and model flexibility, one approach is to fit both a highly flexible and a more constrained model. In this way, we can use cross-validation errors to estimate which direction we should take in the flexibility spectrum to avoid overfitting. Despite the fact that some models are conceptually preferable, our aim is to explore a wide range of models rather than categorically excluding one from the outset. Our aim in fitting both flexible and less flexible models is to find the ideal trade-off between bias and variance and to identify the most appropriate direction within the flexibility spectrum.","metadata":{}},{"cell_type":"markdown","source":"## 5.1 Ridge Multinomial Regression","metadata":{}},{"cell_type":"markdown","source":"We start with a very inflexible model to see if the data needs many predictors. Ridge model can help us understand if we can reduce the predictors to a smaller set, as it shrinks the parameters close, but not entirely to zero, and still showing us how well they can classify emotions. The multinominal model is suited for situations with multiple classes, not just two.\n\nWe expect a Lasso regression to perform similar to Ridge.\n\nFirst, we trained a classification model (Ridge regression) on the cleaned training data using the caret package. Second, we evaluate the model's performance using cross-validation, where we configure model training with 5-fold cross-validation. 75% of the data is used for training, and 25% for validation in each fold. Then we make predictions on the training data using the trained model and reports the results in terms of a confusion matrix  to assess the model's classification performance.","metadata":{}},{"cell_type":"code","source":"# Speed up tuning by using all 4 CPU cores\ndoMC::registerDoMC(cores = 4)\ntrCntrl = caret::trainControl('cv', 5, p = 0.75, allowParallel = TRUE) #cross validation \n\nfit_ridge <- caret::train(x = data_train_clean, \n                          y = factor(y), \n                          method = \"glmnet\", \n                          trControl = trCntrl)\nfit_ridge\n\n# The final values used for the model were alpha = 0.1 and lambda = 0.004413233.\n\n# so the cross validated accuracy is: \nridge_acc <- fit_ridge$results[1,3]","metadata":{"execution":{"iopub.status.busy":"2023-10-19T09:22:37.072441Z","iopub.status.idle":"2023-10-19T09:22:37.072881Z","shell.execute_reply.started":"2023-10-19T09:22:37.072711Z","shell.execute_reply":"2023-10-19T09:22:37.07273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Performance evaluation \npred_ridge = predict(fit_ridge, \n                     data_train_clean,  \n                     type = 'raw')\n\n# Assessing Accuracy in Confusion-Matrix\nconfusion_ridge = caret::confusionMatrix(pred_ridge,factor(y))\nconfusion_ridge","metadata":{"execution":{"iopub.status.busy":"2023-10-19T09:22:37.074631Z","iopub.status.idle":"2023-10-19T09:22:37.074987Z","shell.execute_reply.started":"2023-10-19T09:22:37.074825Z","shell.execute_reply":"2023-10-19T09:22:37.074841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5.2 Linear Discriminant Analysis (LDA)","metadata":{}},{"cell_type":"markdown","source":"LDA is a suitable choice for multiclass problems and can outperform the multinomial model used previously. However, given the complexity of our data, limiting LDA to linear decision boundaries could potentially have a negative impact on accuracy.\n\nWe first applied Linear Discriminant Analysis to the preprocessed training data and evaluated the performance with cross-validation. Besides that, LDA requires a PCA to bring the data to a processable level. Then we used the trained model to make predictions on the training data and reported the results by creating a confusion matrix to assess the classification accuracy of the model. In this way, we were able to thoroughly evaluate the performance of the LDA model.","metadata":{}},{"cell_type":"code","source":"# Speed up tuning by using all 4 CPU cores\ndoMC::registerDoMC(cores = 4)\ntrCntrl = caret::trainControl('cv', 5, p = 0.75, allowParallel = TRUE) #cross validation \n\nfit_lda <- caret::train(x = data_train_clean, \n                        y = factor(y), \n                        method = \"lda\",  # Linear Discriminant Analysis\n                        trControl = trCntrl,\n                        preProcess = \"pca\")\nfit_lda\n\n# crossvalidated accuracy \nlda_acc <- fit_lda$results[1,2]","metadata":{"execution":{"iopub.status.busy":"2023-10-19T09:22:37.076649Z","iopub.status.idle":"2023-10-19T09:22:37.077199Z","shell.execute_reply.started":"2023-10-19T09:22:37.077015Z","shell.execute_reply":"2023-10-19T09:22:37.07704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Performance evaluation \npred_lda = predict(fit_lda, \n                   data_train_clean)\n                   \n# Assessing Accuracy in Confusion-Matrix\nconfusion_lda = caret::confusionMatrix(pred_lda, factor(y))\nconfusion_lda","metadata":{"execution":{"iopub.status.busy":"2023-10-19T09:22:37.078105Z","iopub.status.idle":"2023-10-19T09:22:37.078878Z","shell.execute_reply.started":"2023-10-19T09:22:37.078695Z","shell.execute_reply":"2023-10-19T09:22:37.078716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5.3 Classification Tree","metadata":{}},{"cell_type":"markdown","source":"Now, we fit a classification tree to the data. A classification tree systematically divides a dataset into subsets. In cases where there is a linear relationship between features and classes, other methods such as LDA or QDA tend to outperform classification trees. However, classification trees might be preferred because the interpretability. Trees are easier to explain than other models. They resemble human decision-making and are visually intuitive, making them accessible to non-experts, especially in their smaller forms. ","metadata":{}},{"cell_type":"code","source":"# Speed up tuning by using all 4 CPU cores\ndoMC::registerDoMC(cores = 4)\ntrCntrl = caret::trainControl('cv', 5, p = 0.75, allowParallel = TRUE)\n\n# Fit a classification tree using the rpart method\nfit_tree <- caret::train(x = data_train_clean, \n                         y = y, \n                         method = \"rpart\", \n                         trControl = trCntrl)\nfit_tree\n\n# The final value used for the model was cp = 0.04556355\n\n# cross validated accuracy\ntree_acc <- fit_tree$results[2,2]","metadata":{"execution":{"iopub.status.busy":"2023-10-19T09:22:37.080177Z","iopub.status.idle":"2023-10-19T09:22:37.080697Z","shell.execute_reply.started":"2023-10-19T09:22:37.080509Z","shell.execute_reply":"2023-10-19T09:22:37.080527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Performance evaluation\npred_tree <- predict(fit_tree, data_train_clean, type='raw')\n\n# Assessing Accuracy in Confusion-Matrix\nconfusion_tree <- caret::confusionMatrix(pred_tree, factor(y))\nconfusion_tree","metadata":{"execution":{"iopub.status.busy":"2023-10-19T09:22:37.081783Z","iopub.status.idle":"2023-10-19T09:22:37.082503Z","shell.execute_reply.started":"2023-10-19T09:22:37.082295Z","shell.execute_reply":"2023-10-19T09:22:37.082336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5.5 Support Vector Machine","metadata":{}},{"cell_type":"markdown","source":"Last but not least, a support vector machine analysis is fitted to the data. The primary objective of the support vector machine analysis is to find an optimal hyperplane that best separates different classes in the feature space. This hyperplane, represented as a line in two dimensions and a higher-dimensional space in more complex data, maximizes the margin—the distance between the hyperplane and the nearest data points of each class. The key data points closest to the hyperplane are called support vectors and play a pivotal role in defining the decision boundary. \nThe support vector machine methode is simple, however the disadvantage is that it can not be applied to most data sets. It requires that the classes be separable by a linear boundary.","metadata":{}},{"cell_type":"code","source":"# Speed up tuning by using all 4 CPU cores\ndoMC::registerDoMC(cores = 4)\ntrCntrl = caret::trainControl('cv', 5, p = 0.75, allowParallel = TRUE) \n\nfit_svm <- caret::train(x = data_train_clean, \n                        y = y, \n                        method = \"svmRadial\",\n                        trControl = trCntrl, \n                        preProcess = c(\"center\",\"scale\"),\n                        tuneLength = 10)\n\n\nfit_svm\n\n# The final values used for the model were sigma = 0.0005234634 and C = 16\n\n# so what is the cross validated accuracy here: \nsvm_acc <- fit_svm$results[7,3]","metadata":{"execution":{"iopub.status.busy":"2023-10-19T09:22:37.083628Z","iopub.status.idle":"2023-10-19T09:22:37.084412Z","shell.execute_reply.started":"2023-10-19T09:22:37.084227Z","shell.execute_reply":"2023-10-19T09:22:37.084245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Performance evaluation\npred_svm = predict(fit_svm, data_train_clean, type='raw') \n### Assessing Accuracy in Confusion-Matrix\nconfusion_svm <- confusionMatrix(pred_svm, factor(y))","metadata":{"execution":{"iopub.status.busy":"2023-10-19T09:22:37.085432Z","iopub.status.idle":"2023-10-19T09:22:37.086026Z","shell.execute_reply.started":"2023-10-19T09:22:37.085855Z","shell.execute_reply":"2023-10-19T09:22:37.085872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6.1 Model Comparison","metadata":{}},{"cell_type":"markdown","source":"We compared the fitted models using the accuracy of the cross validation for evaluating on the training data. This way we could determine which model to use for the final predictions on the test set. As we can see in the tabel and in the plot. Support vector maschine does have the best accuracy on the crossvalidated test set. That is also the reason why we chose that model. ","metadata":{}},{"cell_type":"code","source":"# Table: Accuracy\ntable <- data.frame(\n  Model = c(\"Ridge\", \"LDA\", \"Simple Tree\", \"Support Vector Machine\"),\n  Accuracy = c(ridge_acc, lda_acc,tree_acc, svm_acc )\n)\n# Print the table\nprint(table)\n\n# Plot: Accuracy\nplot_accuracy <- ggplot(table, aes(x = Model, y = Accuracy, fill = Model)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(title = \"Accuracy Comparison\",\n       x = \"Model\",\n       y = \"Accuracy\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 12)) +\n  guides(fill = FALSE) +\n  scale_fill_manual(values = c(\"Ridge\" = \"black\", \"LDA\" = \"black\", \"Simple Tree\" = \"black\", \"Support Vector Machine\" = \"green\"))\n\nplot_accuracy","metadata":{"execution":{"iopub.status.busy":"2023-10-19T09:22:37.087031Z","iopub.status.idle":"2023-10-19T09:22:37.087639Z","shell.execute_reply.started":"2023-10-19T09:22:37.087462Z","shell.execute_reply":"2023-10-19T09:22:37.087482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 7. Submissions\n\nThe trained model is used to make predictions on test data, and the results are saved in a CSV file for submission.","metadata":{}},{"cell_type":"code","source":"dim(X_test_features)\ndim(X_test_raw_all)\ndim(data_train_clean)","metadata":{"execution":{"iopub.status.busy":"2023-10-19T09:22:37.088693Z","iopub.status.idle":"2023-10-19T09:22:37.089293Z","shell.execute_reply.started":"2023-10-19T09:22:37.089094Z","shell.execute_reply":"2023-10-19T09:22:37.089119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Make predictions\nprediction = predict(fit_svm, X_test_clean, type='raw')\n\n# Write to file\ntibble(file = rownames(X_test), category = prediction) %>% \n    write_csv(path = \"submission.csv\")\n\n# Check result\ncat(readLines(\"submission.csv\",n=20), sep=\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2023-10-19T09:22:37.090358Z","iopub.status.idle":"2023-10-19T09:22:37.090956Z","shell.execute_reply.started":"2023-10-19T09:22:37.090767Z","shell.execute_reply":"2023-10-19T09:22:37.090793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Divison of labor:\n- FreySlateFeatures - Roman, Lisa\n- Statistical Features (deleted in second round) - Lisa, Charlotte\n- Histogram Features - Lisa, Roman\n- Data Preparation - Lisa, Roman\n- Modelling - Lisa, Charlotte, Roman\n- Description of Models - Lisa, Charlotte\n- Model Comparison -Lisa, Charlotte \n","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section-eleven\"></a>\n# 8. References\n\n​\nPatrick Lucey et al. CK+ (Extended Cohn-Kanade dataset). Retreived from: https://paperswithcode.com/dataset/ck","metadata":{}}]}